# ACP Browser Integration POC - Results

**Date**: 2026-01-25
**Goal**: Test if ACP subprocess approach has acceptable latency (<3s first token) for chat UX
**Status**: COMPLETED âœ…

---

## Executive Summary

**Decision: Use Agent SDK approach instead of ACP**

The POC successfully validated the end-to-end architecture (Chrome extension â†’ WebSocket â†’ subprocess â†’ response streaming), but measured latency is **20x higher than target**.

---

## Test Results

### Latency Metrics

| Metric | Target | Actual | Result |
|--------|--------|--------|--------|
| **First token latency** | < 3,000ms | **59,987ms (~60s)** | âŒ FAILED |
| **Total time** | < 5,000ms | **60,459ms (~60.5s)** | âŒ FAILED |
| **Process spawn overhead** | N/A | ~60s | âš ï¸ Unacceptable |

### What Worked âœ…

1. **Chrome Extension**
   - âœ… Click mode with hover highlights
   - âœ… DOM extraction (element + ancestors)
   - âœ… Side panel UI with chat interface
   - âœ… WebSocket client with auto-reconnect
   - âœ… Dynamic content script injection

2. **WebSocket Communication**
   - âœ… Bidirectional messaging
   - âœ… Connection status updates
   - âœ… Message serialization/deserialization

3. **Server Architecture**
   - âœ… Node.js + TypeScript + Express
   - âœ… WebSocket server on port 3456
   - âœ… Prompt building from UI context
   - âœ… Claude Code subprocess spawning

### What Didn't Work âŒ

1. **Latency**
   - âŒ 60 second first token (vs 3s target)
   - Subprocess spawn + initialization overhead is too high
   - User experience is unacceptable for real-time chat

2. **Response Streaming** (minor)
   - Response content not displayed in UI
   - Likely stdout vs stderr routing issue
   - Not critical since latency is the blocker

---

## Root Cause Analysis

### Why 60 Seconds?

The `claude --print` command takes ~60s to:

1. **Spawn subprocess** - Node.js child_process overhead
2. **Initialize Claude Code** - Load credentials, validate OAuth, initialize SDK
3. **Process prompt** - Full Claude Code startup sequence
4. **Generate response** - Actual AI processing (small portion of total time)

Most of the latency is **initialization overhead**, not AI processing.

---

## Architecture Validation

Despite latency issues, the POC validated key architectural decisions:

| Component | Validation |
|-----------|------------|
| Chrome Extension (Manifest V3) | âœ… Works as designed |
| WebSocket for bidirectional comms | âœ… Reliable, real-time |
| DOM capture + screenshot approach | âœ… Captures precise context |
| Project-local server | âœ… Easy to start/stop |
| Side panel UI | âœ… Good UX integration |

---

## Comparison: ACP vs Agent SDK

| Factor | ACP (Tested) | Agent SDK (Next) |
|--------|--------------|------------------|
| **First token** | ~60s | ~0.5s (estimated) |
| **Process model** | Subprocess per request | Single long-running process |
| **Startup overhead** | ~60s every request | One-time at service start |
| **Streaming** | Complex (stdio pipes) | Native async/await |
| **Memory** | Low (process dies) | Higher (persistent) |
| **Ecosystem** | Open standard | Anthropic-specific |
| **Maintenance** | Stable API | SDK version updates |

---

## Decision

**Proceed with Agent SDK approach** as originally planned in tech-brainstorm docs.

### Rationale

1. **Latency is non-negotiable** - 60s makes the tool unusable
2. **Agent SDK is in-process** - No subprocess spawn overhead
3. **Already verified** - Max subscription OAuth works with Agent SDK
4. **Better streaming** - Native Python async support
5. **FastAPI** - Pairs well with Agent SDK for WebSocket

### Trade-offs Accepted

- âŒ Vendor lock-in to Anthropic SDK (vs open ACP standard)
- âŒ Python instead of Node.js (more language diversity)
- âœ… But 100x better latency is worth it

---

## Lessons Learned

1. **Subprocess overhead matters** - Even "fast" spawns add up
2. **Measure early** - POC saved weeks of wrong-path development
3. **Extension architecture is solid** - Can reuse all frontend code
4. **WebSocket is the right choice** - Real-time, bidirectional, reliable

---

## Next Steps

### Phase 1: Agent SDK Service (Week 1)

- [ ] Scaffold Python FastAPI project
- [ ] Integrate Claude Agent SDK
- [ ] Implement WebSocket server (reuse protocol from POC)
- [ ] Add screenshot storage (.ui-chatter/screenshots/)
- [ ] Test end-to-end with existing Chrome extension

### Phase 2: Polish (Week 2)

- [ ] Session management (multi-tab support)
- [ ] Conversation history (SQLite)
- [ ] Settings inheritance from .claude/settings.json
- [ ] Security hooks (project-scope enforcement)
- [ ] CLI: `ui-chatter serve`

### Phase 3: Documentation & Testing (Week 3)

- [ ] User documentation
- [ ] Test on real projects
- [ ] Edge case handling
- [ ] Performance optimization

---

## Appendix: Test Logs

```
ðŸ’¬ Chat request: I want to increase the font to 16px
[METRIC] First token latency: 59987ms
[METRIC] Total time: 60459ms
```

**Test Environment**:
- OS: macOS (Darwin 25.2.0)
- Node.js: v25.4.0
- Claude Code: (installed via npm)
- Browser: Chrome (Manifest V3 extension)

---

## Files Preserved

POC code is preserved in `poc/` directory for reference:
- `poc/server/` - Node.js ACP server
- `poc/extension/` - Chrome extension (Manifest V3)
- `poc/README.md` - Setup instructions

These files demonstrate the working WebSocket architecture and can be referenced when building the Agent SDK version.
